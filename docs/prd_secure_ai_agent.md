# PRD: Bezpieczny Autonomiczny Agent AI w Lilapu

> **Å¹rÃ³dÅ‚a:** [â€Lokalne nie znaczy bezpieczne"](https://www.kaggle.com/writeups/katarzynadrag/lokalne-nie-znaczy-bezpieczne-clawdbot-i-iluz) Â· [â€Ethical Hacker Mentor"](https://www.kaggle.com/writeups/katarzynadrag/ethical-hacker-mentor-testy) Â· Audyt bezpieczeÅ„stwa Lilapu
>
> **Ostatnia aktualizacja:** 2026-02-28

---

## Status

| Faza | Status | Data |
|------|--------|------|
| Phase 1: Hardening | âœ… Zrobione | 2026-02-28 |
| Phase 3: RAG Sanitization | âœ… Zrobione | 2026-02-28 |
| Phase 2: Validator Layer | â¸ï¸ Gdy agent | â€” |
| Phase 4: Hub & Spoke | â¸ï¸ Gdy agent | â€” |
| Phase 5: Audit Trail | â¸ï¸ Gdy agent | â€” |

> Phase 2-5 wymagane tylko gdy Lilapu zyska autonomiczne features (agent sam decyduje o akcjach). DziÅ› Lilapu jest narzÄ™dziem asystenckim â€” user kontroluje kaÅ¼dÄ… interakcjÄ™.

---

## 1. Problem

Lilapu jest dziÅ› **narzÄ™dziem asystenckim** â€” uÅ¼ytkownik nakazuje, AI odpowiada. Brak autonomii = brak ryzyka agenckiego. Ale roadmap moÅ¼e zakÅ‚adaÄ‡ inteligentniejszÄ… automatyzacjÄ™:

- Proaktywne sugestie na podstawie RAG â†’ agent decyduje KIEDY siÄ™ odezwaÄ‡
- Pipeline OCR â†’ Notatka â†’ Embeddingi â†’ agent decyduje CO Å‚Ä…czyÄ‡
- Auto-podsumowania bez klikniÄ™cia â†’ agent decyduje CO podsumowaÄ‡

KaÅ¼dy krok w stronÄ™ autonomii otwiera wektory z artykuÅ‚u o ClawdBot. Ten dokument definiuje **jak budowaÄ‡ agenta bezpiecznie od poczÄ…tku**.

### 1.1 Implikacje Bielika Open-Source

Lilapu uÅ¼ywa **Bielika** (SpeakLeash, open-source) hostowanego na RunPod zamiast komercyjnego API (OpenAI, Anthropic). To zmienia profil ryzyka:

| | Komercyjne API | Bielik OS (RunPod) |
|---|---|---|
| **Data residency** | Dane lecÄ… do vendora | âœ… ZostajÄ… na Twoim RunPodzie |
| **Zero-retention** | Musisz ufaÄ‡ vendorowi | âœ… Kontrolujesz infra |
| **Fine-tuning na safety** | Ograniczone / drogie | âœ… MoÅ¼esz fine-tunowaÄ‡ na odrzucanie injection |
| **Anti-injection RLHF** | Masywny safety training | âš ï¸ Mniej guardrails â€” **Validator jest jedynÄ… barierÄ…** |
| **Structured output** | Natywne function calling | âš ï¸ vLLM nie gwarantuje JSON â€” **defensywny parser wymagany** |
| **Content filtering** | Wbudowane filtry | âš ï¸ **Twoja odpowiedzialnoÅ›Ä‡** |
| **Model patching** | Vendor Å‚ata za Ciebie | âš ï¸ Musisz Å›ledziÄ‡ i aktualizowaÄ‡ sam |

> **UWAGA:** Z Bielikiem OS nie ma vendor safety net. Gdy zdecydujesz siÄ™ na agenta, **Validator Layer (Phase 2) jest P0**.

---

## 2. Zasady Architektoniczne (do zastosowania gdy agent)

### 2.1 Hub & Spoke zamiast Sequential

```mermaid
graph TB
    O["ğŸ§  Orchestrator<br/>(Router + Project Manager)"]
    S1["ğŸ“ Summarizer<br/>(izolowany kontekst)"]
    S2["ğŸ” RAG Searcher<br/>(izolowany kontekst)"]
    S3["âœï¸ Note Creator<br/>(izolowany kontekst)"]
    S4["ğŸ” Crypto Gate<br/>(E2EE encrypt/decrypt)"]
    
    O --> S1
    O --> S2
    O --> S3
    S1 --> S4
    S2 --> S4
    S3 --> S4
```

**Dlaczego:** KaÅ¼dy sub-agent ma wÅ‚asny, czysty kontekst. Prompt injection w jednej domenie nie â€zaraÅ¼a" innych.

### 2.2 Separacja Cognitive â†” Executive

```
LLM â†’ { action: "save_note", params: {...} }
  â†’ Validator: czy action âˆˆ allowlist? params speÅ‚niajÄ… schemat?
    â†’ Executive: ctx.db.insert(...)
```

**Zasada:** LLM nigdy nie wywoÅ‚uje kodu bezpoÅ›rednio. Zawsze przechodzi przez walidator.

### 2.3 Nominal Determinism (nazwy majÄ… znaczenie)

Orchestrator routuje po **nazwie** agenta, nie po jego instrukcjach. Nazwy muszÄ… byÄ‡ neutralne i opisowe:

| âŒ Å¹le | âœ… Dobrze |
|--------|----------|
| `CodeBreaker` | `security_analyzer` |
| `SmartBot` | `transcription_summarizer` |
| `Helper` | `note_creator_v1` |

---

## 3. Model BezpieczeÅ„stwa (5 warstw)

### Warstwa 1: LLM-Level (Prompt Injection)

| ZagroÅ¼enie | Mitygacja | Status |
|------------|-----------|--------|
| User prompt injection | System prompt **server-side** w `ai.ts` | âœ… Zrobione |
| Indirect prompt injection (z RAG) | `sanitizeRagContext()` â€” strip injection patterns PL/EN | âœ… Zrobione |
| Jailbreak â†’ niechciana akcja | **Validator layer** â€” gdy agent | â¸ï¸ Phase 2 |
| Halucynacja â†’ â€realne zdarzenie" | Agent nie ma efektÃ³w ubocznych bez Validator | â¸ï¸ Phase 2 |

### Warstwa 2: Memory-Level (Zatrucie pamiÄ™ci)

| ZagroÅ¼enie | Mitygacja | Status |
|------------|-----------|--------|
| Poisoned input â†’ pamiÄ™Ä‡ agenta | Lilapu **nie ma** autonomicznej pamiÄ™ci | âœ… By design |
| Manipulacja embeddingÃ³w | Per-user, per-project z ownership verification | âœ… Zrobione |
| Context pollution (Token Bleed) | Hub & Spoke â€” gdy agent | â¸ï¸ Phase 4 |

### Warstwa 3: System-Level (Izolacja)

| ZagroÅ¼enie | Mitygacja | Status |
|------------|-----------|--------|
| Shell access | Agent **nie ma** â€” nigdy | âœ… By design |
| File system access | Tylko Convex DB | âœ… By design |
| Network requests | Hardcoded RunPod endpoints, server-side | âœ… By design |
| Privilege escalation | `requireAuth()` we wszystkich actions | âœ… Zrobione |

### Warstwa 4: Psychologiczna

| ZagroÅ¼enie | Mitygacja | Status |
|------------|-----------|--------|
| â€Lokalny = bezpieczny" false sense | UI komunikuje: gdzie dane przetwarzane, co jest E2EE | âœ… By design |
| Blind trust w AI output | Banner â€Wygenerowane przez AI" | â¸ï¸ Phase 5 |
| Auto-actions without awareness | Activity log â€” gdy agent | â¸ï¸ Phase 5 |

### Warstwa 5: External Exploitation

| ZagroÅ¼enie | Mitygacja | Status |
|------------|-----------|--------|
| Agent jako wektor sieciowy | Brak dostÄ™pu do sieci poza hardcoded endpoints | âœ… By design |
| Exposed endpoints | Auth + API keys + CORS whitelist | âœ… Zrobione |
| Data exfiltration via AI | E2EE, zero plaintext embeddings | âœ… By design |

---

## 4. Co zostaÅ‚o zrobione (Phase 1 + 3)

### Phase 1: Hardening (2026-02-28) âœ…

| Zmiana | Plik |
|--------|------|
| Auth guards (`requireAuth`) + input size limits | `ai.ts` (8 actions), `rag.ts` (3 actions) |
| Timing-safe key comparison (XOR) | `http.ts` |
| `getAudioUrl` ownership check | `transcriptions.ts` |
| Rate limiting + payload size limits | `http.ts` |
| Input validation (string lengths) | `transcriptions.ts` (via `validation.ts`) |
| Email validation | `waitlist.ts` |
| UsuniÄ™cie `'unsafe-eval'` z CSP | `tauri.conf.json` |
| Error message masking | `server.py` |
| CORS localhost â†’ `ALLOW_LOCALHOST` env | `server.py` |
| Payload size limits (WS + HTTP) | `server.py` |

### Phase 3: RAG Sanitization (2026-02-28) âœ…

| Zmiana | Plik |
|--------|------|
| `sanitizeRagContext()` â€” 16 wzorcÃ³w PL/EN | `ai.ts` |
| Injection patterns: `[system]`, `ignore previous`, `ignoruj poprzednie`, `you are now`, `jesteÅ› teraz`, `act as`, `udawaj Å¼e`, itd. | Zintegrowane z `chat` action |

---

## 5. Co pozostaje (gdy agent)

### Phase 2: Validator Layer + Red-Team Testing (~12h)

- `agentValidator.ts` â€” allowlist dozwolonych akcji + schema validation
- Defensywny JSON parser dla Bielika (tolerancyjny input, strict validation)
- Red-team testing z injection payloads (PL/EN/mixed, JSON smuggling)

### Phase 4: Hub & Spoke Orchestrator (~16h)

- Orchestrator z routingiem do sub-agentÃ³w
- Sub-agents: Summarizer, RAG Searcher, Note Creator
- Context isolation per sub-agent + Compaction strategy
- E2EE Crypto Gate (sub-agents operujÄ… na plaintext, Gate szyfruje I/O)

### Phase 5: Audit Trail & UI (~8h)

- `agentAuditLog` tabela w Convex
- Activity log UI â€” historia autonomicznych akcji agenta
- AI content banners + Cost guard monitoring

---

## 6. Kluczowe Decyzje

| Decyzja | WybÃ³r | Uzasadnienie |
|---------|-------|--------------|
| LLM backend | **Bielik OS (self-hosted)** | Privacy-first, zero data do 3rd party |
| Agent memory | **Brak**, opt-in z user confirmation w przyszÅ‚oÅ›ci | GÅ‚Ã³wny wektor ataku z artykuÅ‚u ClawdBot |
| Shell/FS access | **Nigdy** | Lilapu â‰  agent systemowy |
| LLM â†’ DB writes | **Przez Validator** (gdy agent) | Bielik OS nie ma vendor safety net |
| Structured output | **Defensywny parser** (gdy agent) | vLLM nie gwarantuje JSON |
| Error handling | **Masked for user, detailed in logs** | Prevent infra leakage |
| Model updates | **Quarterly review** | Brak auto-patching |

---

> **BezpieczeÅ„stwo nie jest funkcjÄ… geografii danych, lecz funkcjÄ… architektury.**
> â€” Katarzyna DrÄ…g, Kaggle 2026
